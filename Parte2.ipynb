{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de opiniones sobre Películas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se trabajará con un dataset del sitio <b>Rotten Tomatoes</b>, el cual consta de opiniones de la gente sobre alguna película, en texto en ingles. Se intentará predecir si la opinión de la persona es una opinión $positiva$ o $negativa$ (1 y -1) en base a un análisis de las palabras utilizadas en la opinion. Se trabaja además con operaciones de stopwords, stemming y lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3554, 2)\n",
      "(3554, 2)\n",
      "   Sentiment                                               Text\n",
      "0         -1  everything's serious , poetic , earnest and --...\n",
      "1         -1  narratively , trouble every day is a plodding ...\n",
      "2          1  a truly wonderful tale combined with stunning ...\n",
      "3          1  jason patric and ray liotta make for one splen...\n",
      "4         -1  haneke keeps us at arm's length . guided more ...\n",
      "      Sentiment                                               Text\n",
      "3549          1  a fascinating documentary about the long and e...\n",
      "3550          1  the filmmakers' eye for detail and the high st...\n",
      "3551          1  throwing caution to the wind with an invitatio...\n",
      "3552         -1  �a big , baggy , sprawling carnival of a movie...\n",
      "3553          1  an incendiary , deeply thought-provoking look ...\n",
      "TRAINING-Cantidad clase negativa:  1784\n",
      "TRAINING-Cantidad clase positiva:  1770\n",
      "TEST-Cantidad clase negativa:  1803\n",
      "TEST-Cantidad clase positiva:  1751\n"
     ]
    }
   ],
   "source": [
    "# Importar los datos y ver sus dimensiones\n",
    "import urllib\n",
    "import pandas as pd\n",
    "train_data_url = \"http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.train\"\n",
    "test_data_url = \"http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.dev\"\n",
    "train_data_f = urllib.urlretrieve(train_data_url, \"train_data.csv\")\n",
    "test_data_f = urllib.urlretrieve(test_data_url, \"test_data.csv\")\n",
    "ftr = open(\"train_data.csv\", \"r\")\n",
    "fts = open(\"test_data.csv\", \"r\")\n",
    "rows = [line.split(\" \",1) for line in ftr.readlines()]\n",
    "train_df = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "train_df['Sentiment'] = pd.to_numeric(train_df['Sentiment'])\n",
    "rows = [line.split(\" \",1) for line in fts.readlines()]\n",
    "test_df = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "test_df['Sentiment'] = pd.to_numeric(test_df['Sentiment'])\n",
    "print train_df.shape\n",
    "print test_df.shape\n",
    "print train_df.head()\n",
    "print test_df.tail()\n",
    "\n",
    "#Contar cantidad de cada clase   \n",
    "print \"TRAINING-Cantidad clase negativa: \",train_df[\"Sentiment\"].tolist().count(-1)\n",
    "print \"TRAINING-Cantidad clase positiva: \",train_df[\"Sentiment\"].tolist().count(1)\n",
    "print \"TEST-Cantidad clase negativa: \",test_df[\"Sentiment\"].tolist().count(-1)\n",
    "print \"TEST-Cantidad clase positiva: \",test_df[\"Sentiment\"].tolist().count(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primera parte se carga los datos y se almacenan en un archivo local .csv. Luego se muestra un extracto del dataset donde se pueden ver opiniones ($text$) y su polaridad ($sentiment$).\n",
    "\n",
    "La cantidad de datos en el training set de la clase negativa y positiva son 1784 y 1770 respectivamente. La cantidad de datos en el test set de la clase negativa y positiva son 1803 y 1751 respectivamente. Se puede observar que la cantidad de datos por clase es homogéneo, aportando a que el training set tenga un aprendizaje equitativo en cuanto a las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------word_extractor---------------------\n",
      " love eat cake\n",
      " love eat cake\n",
      " love eat cake\n",
      " love eat cake\n",
      " n't love eat cake\n",
      " walk moon\n",
      " see big foot\n",
      " saw dog eat cat\n",
      " dog call pluto\n",
      " eat cake\n",
      " eat lot jelli\n",
      " eat lot cake\n",
      "---------------------word_extractor_sin_stemming---------------------\n",
      " love eat cake\n",
      " love eating cake\n",
      " loved eating cake\n",
      " love eating cake\n",
      " n't love eating cake\n",
      " walking moon\n",
      " see big foot\n",
      " saw dog eat cat\n",
      " dog called pluto\n",
      " eating cake\n",
      " eat lots jellies\n",
      " eat lots cakes\n"
     ]
    }
   ],
   "source": [
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def word_extractor(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ stemmer.stem(word.lower()) \\\n",
    "        for word in word_tokenize(text.decode('utf-8', 'ignore')) ]\n",
    "    for word in wordtokens:\n",
    "        if word not in commonwords:\n",
    "            words+=\" \"+word\n",
    "    return words\n",
    "def word_extractor_sin_stemming(text):\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ word.lower() \\\n",
    "        for word in word_tokenize(text.decode('utf-8', 'ignore')) ]\n",
    "    for word in wordtokens:\n",
    "        if word not in commonwords:\n",
    "            words+=\" \"+word\n",
    "    return words\n",
    "\n",
    "print \"---------------------word_extractor---------------------\"\n",
    "print word_extractor(\"I love to eat cake\")\n",
    "print word_extractor(\"I love eating cake\")\n",
    "print word_extractor(\"I loved eating the cake\")\n",
    "print word_extractor(\"I do not love eating cake\")\n",
    "print word_extractor(\"I don't love eating cake\")\n",
    "# propias\n",
    "print word_extractor(\"They are walking in the moon\")\n",
    "print word_extractor(\"I see a big foot\")\n",
    "print word_extractor(\"I saw my dog eat my cat\")\n",
    "print word_extractor(\"I have a dog called Pluto\")\n",
    "print word_extractor(\"I am eating cake\")\n",
    "print word_extractor(\"I eat lots of jellies\")\n",
    "print word_extractor(\"I eat a lots of cakes\")\n",
    "\n",
    "print \"---------------------word_extractor_sin_stemming---------------------\"\n",
    "print word_extractor_sin_stemming(\"I love to eat cake\")\n",
    "print word_extractor_sin_stemming(\"I love eating cake\")\n",
    "print word_extractor_sin_stemming(\"I loved eating the cake\")\n",
    "print word_extractor_sin_stemming(\"I do not love eating cake\")\n",
    "print word_extractor_sin_stemming(\"I don't love eating cake\")\n",
    "# propias\n",
    "print word_extractor_sin_stemming(\"They are walking in the moon\")\n",
    "print word_extractor_sin_stemming(\"I see a big foot\")\n",
    "print word_extractor_sin_stemming(\"I saw my dog eat my cat\")\n",
    "print word_extractor_sin_stemming(\"I have a dog called Pluto\")\n",
    "print word_extractor_sin_stemming(\"I am eating cake\")\n",
    "print word_extractor_sin_stemming(\"I eat lots of jellies\")\n",
    "print word_extractor_sin_stemming(\"I eat a lots of cakes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que al aplicar el algoritmo $word\\_extractor()$ captura el tronco léxico base de cada palabra en las distintas oraciones. En los 4 primeros ejemplos se obtiene el mismo tronco léxico para las oraciones, puesto que se trata solamente de palabras que se le agrega el \"ing\" o el \"ed\" al final. Tambien se observa que existe diferencia entre poner \"do not\" y \"don't\" obteniéndose distintas palabras como resultado, en el primer caso se consideran palabras separadas por lo que son eliminadas por la función <b>stopwords</b>, la cual elimina palabras que no aportan al significado, es decir, palabras sin información o de significado vacío como los artículos, los pronombres o las preposiciones. La importancia de borrar estas palabras es para hacer más eficiente el análisis de clasificación, puesto que así no se pierde tiempo procesando y guardando estas palabras en el algoritmo.\n",
    "\n",
    "Si no se aplica <i>stemming</i>, las palabras no son reducidas a su tronco léxico por lo que quedan con su \"extención\" (-ing, -s, -ies, -es, -ed, entre otros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love eat cake\n",
      " love eating cake\n",
      " loved eating cake\n",
      " love eating cake\n",
      " n't love eating cake\n",
      " walking moon\n",
      " see big foot\n",
      " saw dog eat cat\n",
      " dog called pluto\n",
      " eating cake\n",
      " eat lot jelly\n",
      " eat lot cake\n"
     ]
    }
   ],
   "source": [
    "# Funcion igual a la anterior, pero con lematizing en vez de stemming\n",
    "def word_extractor2(text):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ wordlemmatizer.lemmatize(word.lower()) \\\n",
    "            for word in word_tokenize(text.decode('utf-8','ignore')) ]\n",
    "    for word in wordtokens:\n",
    "        if word not in commonwords:\n",
    "            words+=\" \"+word\n",
    "    return words\n",
    "def word_extractor_sin_stop(text):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "    wordtokens = [ wordlemmatizer.lemmatize(word.lower()) \\\n",
    "        for word in word_tokenize(text.decode('utf-8', 'ignore')) ]\n",
    "    words = \"\"\n",
    "    for word in wordtokens:\n",
    "        words+=\" \"+word\n",
    "    return words\n",
    "print word_extractor2(\"I love to eat cake\")\n",
    "print word_extractor2(\"I love eating cake\")\n",
    "print word_extractor2(\"I loved eating the cake\")\n",
    "print word_extractor2(\"I do not love eating cake\")\n",
    "print word_extractor2(\"I don't love eating cake\")\n",
    "#propias\n",
    "print word_extractor2(\"They are walking in the moon\")\n",
    "print word_extractor2(\"I see a big foot\")\n",
    "print word_extractor2(\"I saw my dog eat my cat\")\n",
    "print word_extractor2(\"I have a dog called Pluto\")\n",
    "print word_extractor2(\"I am eating cake\")\n",
    "print word_extractor2(\"I eat lots of jellies\")\n",
    "print word_extractor2(\"I eat a lot of cakes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de la función $word\\_extractor2()$ utiliza <i>lemmatization</i> el cual reduce las palabras asociándolas a alguna palabra del diccionario, eliminando los finales de las palabras que cambian el significado de estas, reduciendolas al una forma canónica.\n",
    "\n",
    "Se puede ver la diferencia entre <i>lemmatization</i> y <i>stemming</i> en los ejemplos, ya que la primera deja intacto los finales -ed y -ing. Ambos eliminan los finales -es y -s, como es el caso de \"jellies\" a \"jelly\" y \"cakes\" a \"cake\", sin embargo la forma mediante <i>stemming</i> es mas reducida, ya que elimina también los finales -ed y -ing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de palabras en el diccionario: 9663.000000\n",
      "==========  =========  ============  ===  ======  =========  ============\n",
      "  Training  Palabra      Frecuencia  #      Test  Palabra      Frecuencia\n",
      "==========  =========  ============  ===  ======  =========  ============\n",
      "         1  film                566  #         1  film                558\n",
      "         2  movie               481  #         2  movie               540\n",
      "         3  one                 246  #         3  one                 250\n",
      "         4  like                245  #         4  ha                  238\n",
      "         5  ha                  224  #         5  like                230\n",
      "         6  make                183  #         6  story               197\n",
      "         7  story               176  #         7  character           175\n",
      "         8  character           163  #         8  time                165\n",
      "         9  comedy              145  #         9  make                161\n",
      "        10  time                143  #        10  comedy              134\n",
      "==========  =========  ============  ===  ======  =========  ============\n"
     ]
    }
   ],
   "source": [
    "# Representacion vectorial del texto de entrenamiento y el de pruebas\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0) #0 y 1\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0) # 0 y 1\n",
    "vocab = vectorizer.get_feature_names() #se crea en base al texts train\n",
    "dist=list(np.array(features_train.sum(axis=0)).reshape(-1,))\n",
    "dist2=list(np.array(features_test.sum(axis=0)).reshape(-1,))\n",
    "\n",
    "# Se ordenan las palabras por cantidad\n",
    "lista_train = zip(vocab, dist)\n",
    "lista_train.sort(key=lambda x: x[1])\n",
    "lista_train.reverse()\n",
    "# Se ordenan las palabras por cantidad\n",
    "lista_test = zip(vocab, dist2)\n",
    "lista_test.sort(key=lambda x: x[1])\n",
    "lista_test.reverse()\n",
    "\n",
    "N = 10\n",
    "pals_train = []\n",
    "count_train =[]\n",
    "pals_test = []\n",
    "count_test = []\n",
    "for i in range(N):\n",
    "    tag, count = lista_train[i]\n",
    "    pals_train.append(tag)\n",
    "    count_train.append(count)\n",
    "    tag_test, count_t = lista_test[i]\n",
    "    pals_test.append(tag_test)\n",
    "    count_test.append(count_t)    \n",
    "print \"Cantidad de palabras en el diccionario: %f\"%(len(vocab))\n",
    "\n",
    "a = [range(1,11),pals_train,count_train, [\"#\",\"#\",\"#\",\"#\",\"#\",\"#\",\"#\",\"#\",\"#\",\"#\"], range(1,11), pals_test,count_test]\n",
    "table =  zip(*a)\n",
    "from tabulate import tabulate\n",
    "print tabulate(table, headers=[\"Training\",\"Palabra\",\"Frecuencia\",\"#\", \"Test\",\"Palabra\",\"Frecuencia\"],  tablefmt=\"rst\")\n",
    "a = [pals_test,count_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se genera una representación vectorial de los datos de entrenamiento y de prueba, ajustado a los datos de entrenamiento, donde cada eje representa a una palabra, indicando un 1 si esa palabra está presente en la opinion de la persona, es decir, es un vector de las palabras que contiene la opinion de la persona.\n",
    "\n",
    "Se puede ver que el <b>diccionario</b> con el cual se trabajará (<i>vocab</i>) es dependiente del training set, por lo que dependerá en gran parte de la diversidad de palabras que se utilicen en este set, debiendo presentar una gran cantidad de datos y con una variedad de lenguaje lo mas amplia posible, así para que no existan palabras en el test set que no las reconozca el diccionario ya que no están presentes.\n",
    "\n",
    "La cantidad de palabras en el diccionario es 9663. Dentro de estas, las más frecuentes para el training set y para el test set son presentadas en la tabla anterior, donde las 10 palabras obtenidas en cada set son las mismas pero con distinta frecuencia. Se puede ver como las palabras más repetidas son las más relacionadas con la temática (películas) ya que son \"film\", \"movie\", \"story\",\"character\",\"comedy\". Hay algunas palabras bastante repetidas que no entregan mucho significado, tal como \"ha\" o como \"one\". 1 de cada 7 opiniones presenta la palabra \"film\". Se puede ver como una palabra por si sola no entrega el suficiente significado para determinar si una opinion es positiva o negativa, ya que estas 10 palabras más repetidas son un ejemplo de que no lo hacen. Se tiene el ejemplo de la palabra \"like\" la cual en un contexto distinto es utilizado con distintos propósitos, tales como \"I like the movie\" o \"I didn't like the movie\", por lo que por sí sola no entrega la información necesaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def representacion(forma):\n",
    "    if forma == \"normal\":\n",
    "        texts_train = [word_extractor_sin_stop(text) for text in train_df.Text]\n",
    "        texts_test = [word_extractor_sin_stop(text) for text in test_df.Text]\n",
    "    elif forma == \"stem\":\n",
    "        texts_train = [word_extractor(text) for text in train_df.Text]\n",
    "        texts_test = [word_extractor(text) for text in test_df.Text]\n",
    "    elif forma == \"lem\":\n",
    "        texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "        texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "    vectorizer.fit(np.asarray(texts_train))\n",
    "    features_train = vectorizer.transform(texts_train)\n",
    "    features_test = vectorizer.transform(texts_test)\n",
    "    labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0) #0 y 1\n",
    "    labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0) # 0 y 1\n",
    "    return features_train,labels_train,features_test,labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función anterior es utilizada para generar la representación vectorial mediante los distintos procesos de reducción léxica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,precision_recall_fscore_support\n",
    "# Funcion que evalua el desempeño de un clasificador generico en el conjunto de entrenamiento y de pruebas\n",
    "def score_the_model(model,x,y,xt,yt,text):\n",
    "    acc_tr = model.score(x,y)\n",
    "    acc_test = model.score(xt[:-1],yt[:-1])\n",
    "    print \"Training Accuracy %s: %f\"%(text,acc_tr)\n",
    "    print \"Test Accuracy %s: %f\"%(text,acc_test)\n",
    "    print \"Detailed Analysis Testing Results ...\"\n",
    "    print(classification_report(yt, model.predict(xt), target_names=['+','-']))\n",
    "    \n",
    "#Funcion que calcula los errores de un modelo\n",
    "def errors(model,x,y,xt,yt): \n",
    "    yhat = model.predict(x)\n",
    "    yhat_test = model.predict(xt)\n",
    "    error = mis_class(yhat,y)\n",
    "    terror = mis_class(yhat_test,yt)\n",
    "    return error, terror\n",
    "def mis_class(yhat,y):\n",
    "    miss = [ 1 if(i != j) else 0  \n",
    "            for i,j in zip(yhat,y)]\n",
    "    return np.mean(miss) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función presentada anteriormente ($classification\\_report()$) calcula 4 métricas (precision, recall, f1-score, support). Cada métrica es calculada de forma independiente para cada clase, donde el significado de <b> precision</b> es una tasa/razón entre los <i>true positive</i> y el resto de los positivos (<i>true positive + false positive</i>), en otras palabras representa la habilidad del clasificador en no etiquetar como clase \"interna\" a una clase \"externa\". El significado de <b>recall</b> tasa/razón entre los <i>true positive</i> y el resto de la clase \"interna\" (<i> true positive + false negative</i>), esto representa la habilidad del clasificador en no dejar fuera los ejemplos de la clase propia, es decir, etiquetar correctamente los de la clase \"interna\" . <b>f1-score</b> realiza un promedio harmónico/ponderado entre las métricas de precision y recall. Finalmente <b>support</b> entrega la cantidad de ejemplos asignadas a cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT STOP WORDS and WITH LEMM\n",
      "Training Accuracy BernoulliNB: 0.955262\n",
      "Test Accuracy BernoulliNB: 0.748663\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.74      0.75      1803\n",
      "          -       0.74      0.76      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.044738\n",
      "Error (Misclassification) Test: 0.251266\n",
      "WITH LEMMATISATION\n",
      "Training Accuracy BernoulliNB: 0.958638\n",
      "Test Accuracy BernoulliNB: 0.738531\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.041362\n",
      "Error (Misclassification) Test: 0.261396\n",
      "WITH STEMMING\n",
      "Training Accuracy BernoulliNB: 0.942881\n",
      "Test Accuracy BernoulliNB: 0.747819\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.74      0.75      1803\n",
      "          -       0.74      0.75      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.057119\n",
      "Error (Misclassification) Test: 0.252110\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "def do_NAIVE_BAYES(x,y,xt,yt):\n",
    "    model = BernoulliNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"BernoulliNB\")\n",
    "    return model\n",
    "errors_bayes = []\n",
    "accuracy_bayes = []\n",
    "\n",
    "tipos = [\"normal\",\"lem\",\"stem\"]\n",
    "descripcion = [\"WITHOUT STOP WORDS and WITH LEMM\", \"WITH LEMMATISATION\",\"WITH STEMMING\"]\n",
    "for (r,d) in zip(tipos,descripcion):\n",
    "    print d\n",
    "    features_train,labels_train,features_test,labels_test = representacion(r)\n",
    "    model=do_NAIVE_BAYES(features_train,labels_train,features_test,labels_test)\n",
    "    \n",
    "    #calculan y guardan los errores de entrenamiento y prueba\n",
    "    error,terror = errors(model,features_train,labels_train,features_test,labels_test)\n",
    "    errors_bayes.append([error,terror])\n",
    "    print \"Error (Misclassification) Training: %f\"%(error)\n",
    "    print \"Error (Misclassification) Test: %f\"%(terror)\n",
    "    \n",
    "    #valores de retornos agregados por datos requeridos en grafico\n",
    "    acc = model.score(features_test,labels_test)\n",
    "    acct = model.score(features_train,labels_train)\n",
    "    prec_rec = precision_recall_fscore_support(labels_test,model.predict(features_test))[:1]\n",
    "    datos = [acc,acct] + list(prec_rec[0])\n",
    "    accuracy_bayes.append(datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior se ajustó un modelo <b>Naive Bayes</b>, el cual presenta sus desempeños en los distintos sets, además de información extra acerca del desempeño en cada clase. Agregando al final el error con función de pérdida <i> misclassification</i> para cada set.\n",
    "\n",
    "<i>stemming</i> tiene un desempeño mejor en el test set, entregando una precisión del <b>74,78 %</b>, por otro lado <i>lemmatisation</i> por otro lado se comporta mejor en el training set. En base a la información detallada sobre resultados en el test set se puede ver que <i>stemming</i> tiene un mejor comportamiento, esto es explicado ya que como se vio anteriormente este proceso realiza un corte a la palabra mas brusco, reduciéndola más que <i>lemma</i>, dejando información más significativa en cuanto al léxico (mas \"pura\"). El proceso de <i>lemmatisation</i> al dejar terminaciones como -ing, -ed, produce un sesgo sobre los datos, ya que si está presente una palabra en el training set como \"walking\", el modelo la asignará distinta a la palabra \"walk\", perdiéndo la información de que estas palabras significan lo mismo. Para el caso de <i>stemming</i> a estas palabras le asignará la misma probabilidad ya que son consideradas la misma (\"walk\"). \n",
    "\n",
    "Para el caso de filtrar <b>stopwords</b> en el proceso del modelo este presenta un mejor desempeño sobre el test set, esto es contradictorio a lo esperado ya que se espera que al eliminar estas palabras que no entregan información el modelo pueda predecir con mejor exactitud. Esta contradicción se puede explicar por los supuestos de naive bayes, ya que la probabilidad de clasificar una frase, es la probabilidad independiente de cada una de las palabras presentes en la frase, con esto en mente se pudo tener el caso que palabras sin información como \"and\", \"of\", \"the\", \"or\" ayudan a clasificar correctamente la frase, siendo algo totalmente aleatorio dependiendo del training set, ya que esas palabras podrían ir en cualquier contexto, positivas o negativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00749361  0.99250639] a movie that at its best doesn't just make the most out of its characters' flaws but insists on the virtue of imperfection .\n",
      "\n",
      "[  1.37058436e-05   9.99986294e-01] a quietly reflective and melancholy new zealand film about an eventful summer in a 13-year-old girl's life .\n",
      "\n",
      "[ 0.99559512  0.00440488] the movie's plot is almost entirely witless and inane , carrying every gag two or three times beyond its limit to sustain a laugh .\n",
      "\n",
      "[ 0.0132626  0.9867374] the urban landscapes are detailed down to the signs on the kiosks , and the color palette , with lots of somber blues and pinks , is dreamy and evocative .\n",
      "\n",
      "[ 0.82094699  0.17905301] barry sonnenfeld owes frank the pug big time\n",
      "\n",
      "[ 0.05083827  0.94916173] the film is filled with humorous observations about the general absurdity of modern life as seen through the eyes outsiders , but deftly manages to avoid many of the condescending stereotypes that so often plague films dealing with the mentally ill .\n",
      "\n",
      "[ 0.97769163  0.02230837] the master of disguise represents adam sandler's latest attempt to dumb down the universe .\n",
      "\n",
      "[ 0.11342201  0.88657799] ice cube holds the film together with an engaging and warm performance . . .\n",
      "\n",
      "[ 0.02039388  0.97960612] children may not understand everything that happens -- i'm not sure even miyazaki himself does -- but they will almost certainly be fascinated , and undoubtedly delighted .\n",
      "\n",
      "[  2.36895420e-05   9.99976310e-01] sandra nettelbeck beautifully orchestrates the transformation of the chilly , neurotic , and self-absorbed martha as her heart begins to open .\n",
      "\n",
      "[ 0.29698359  0.70301641] equilibrium is what george orwell might have imagined had today's mood-altering drug therapy been envisioned by chemists in 1949 .\n",
      "\n",
      "[ 0.3345653  0.6654347] full of surprises .\n",
      "\n",
      "[ 0.82730079  0.17269921] workmanlike , maybe , but still a film with all the elements that made the other three great , scary times at the movies .\n",
      "\n",
      "[ 0.96215088  0.03784912] . . . pays tribute to heroes the way julia roberts hands out awards--with phony humility barely camouflaging grotesque narcissism .\n",
      "\n",
      "[ 0.04672814  0.95327186] although frailty fits into a classic genre , in its script and execution it is a remarkably original work .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que existen ciertas opiniones que solo relatan hechos, sin tener una inclinación positiva o negativa a las cuales generalmente se les asigna una probabilidad equitativa entre las etiquetas de las clases. En otros casos se muestra una clara inclinación hacia una opinion positiva o negativa y el clasificador asigna la probabilidad correspondiente. En general el clasificador Naive Bayes asigna probabilidades correctas a cada opinión, basándose en el producto independiente de la probabilidad de cada palabra que aparece en la opinión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT STOP WORDS and WITH LEMM\n",
      "Training Accuracy MULTINOMIAL: 0.955543\n",
      "Test Accuracy MULTINOMIAL: 0.747537\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.75      0.75      1803\n",
      "          -       0.74      0.74      0.74      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.044457\n",
      "Error (Misclassification) Test: 0.252392\n",
      "WITH LEMMATISATION\n",
      "Training Accuracy MULTINOMIAL: 0.959482\n",
      "Test Accuracy MULTINOMIAL: 0.740782\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.040518\n",
      "Error (Misclassification) Test: 0.259145\n",
      "WITH STEMMING\n",
      "Training Accuracy MULTINOMIAL: 0.942319\n",
      "Test Accuracy MULTINOMIAL: 0.749789\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.75      0.75      1803\n",
      "          -       0.74      0.75      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.057681\n",
      "Error (Misclassification) Test: 0.250141\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "def do_MULTINOMIAL(x,y,xt,yt):\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"MULTINOMIAL\")\n",
    "    return model\n",
    "errors_multi= []\n",
    "accuracy_multi = []\n",
    "\n",
    "tipos = [\"normal\",\"lem\",\"stem\"]\n",
    "descripcion = [\"WITHOUT STOP WORDS and WITH LEMM\", \"WITH LEMMATISATION\",\"WITH STEMMING\"]\n",
    "for (r,d) in zip(tipos,descripcion):\n",
    "    print d\n",
    "    features_train,labels_train,features_test,labels_test = representacion(r) #representacion\n",
    "    model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test) #se ejecuta el modelo\n",
    "    \n",
    "    #calculan y guardan los errores de entrenamiento y prueba\n",
    "    error,terror = errors(model,features_train,labels_train,features_test,labels_test)\n",
    "    errors_multi.append([error,terror])\n",
    "    print \"Error (Misclassification) Training: %f\"%(error)\n",
    "    print \"Error (Misclassification) Test: %f\"%(terror)\n",
    "    \n",
    "    #valores de retornos agregados por datos requeridos en grafico\n",
    "    acc = model.score(features_test,labels_test)\n",
    "    acct = model.score(features_train,labels_train)\n",
    "    prec_rec = precision_recall_fscore_support(labels_test,model.predict(features_test))[:1]\n",
    "    datos = [acc,acct] + list(prec_rec[0])\n",
    "    accuracy_multi.append(datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior se ajustó un modelo <b>Naive Bayes Multinomial</b>, el cual presenta sus desempeños en los distintos sets, además de información extra acerca del desempeño en cada clase. Agregando al final el error con función de pérdida misclassification para cada set.\n",
    "\n",
    "<i>stemming</i> tiene un desempeño mejor en el test set entregando una precisión del <b>74,98 %</b>, <i>lemmatisation</i> por otro lado se comporta mejor en el training set, similar al caso de Naive Bayes discutido anteriormente. Se presentan los mismos argumentos del porqué <i>stemming</i> se comporta mejor sobre el test set, debido al reduce de las palabras a una estructura más pura. <i>lemma</i> se comporta mejor sobre el training set debido a que este set está sesgado hacia la información con las palabras reducidas según <i>lemma</i>.\n",
    "\n",
    "Para este caso el filtrar el eliminado de <b>stopwords</b> también produce un efecto contradictorio a lo esperado, como es el caso de Naive Bayes. Por lo que se piensa que es un suceso casual producido por el training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.32421864  0.67578136] this franchise has not spawned a single good film . the crap continues .\n",
      "\n",
      "[ 0.90392584  0.09607416] comes across as a fairly weak retooling .\n",
      "\n",
      "[ 0.64892822  0.35107178] flavorful and romantic , you could call this how martha got her groove back -- assuming , that is , she ever had one to begin with .\n",
      "\n",
      "[ 0.95974086  0.04025914] if swimfan does catch on , it may be because teens are looking for something to make them laugh .\n",
      "\n",
      "[ 0.55947259  0.44052741] the film grows on you . and how .\n",
      "\n",
      "[ 0.92402891  0.07597109] that zhang would make such a strainingly cute film -- with a blind orphan at its center , no less -- indicates where his ambitions have wandered .\n",
      "\n",
      "[ 0.57232973  0.42767027] these people wouldn't know subtle characterization if it put on a giant furry monster costume and then gave them a lapdance .\n",
      "\n",
      "[ 0.52960649  0.47039351] summer's far too fleeting to squander on offal like this .\n",
      "\n",
      "[ 0.58510856  0.41489144] it's so underwritten that you can't figure out just where the other characters , including ana's father and grandfather , come down on the issue of ana's future .\n",
      "\n",
      "[ 0.87382389  0.12617611] without a strong script and energetic acting , dogma films can produce the same sleep-inducing effects as watching your neighbor's home videos .\n",
      "\n",
      "[ 0.84561012  0.15438988] to get at the root psychology of this film would require many sessions on the couch of dr . freud .\n",
      "\n",
      "[ 0.39817709  0.60182291] go see it and enjoy .\n",
      "\n",
      "[ 0.04881163  0.95118837] 'frailty \" starts out like a typical bible killer story , but it turns out to be significantly different ( and better ) than most films with this theme .\n",
      "\n",
      "[ 0.47779644  0.52220356] this is a harrowing movie about how parents know where all the buttons are , and how to push them .\n",
      "\n",
      "[ 0.05934057  0.94065943] stands as a document of what it felt like to be a new yorker -- or , really , to be a human being -- in the weeks after 9/11 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ver lo de arriba iwal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EFFECT OF C IN THE MODEL\n",
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.784468\n",
      "Test Accuracy LOGISTIC: 0.678863\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.67      0.73      0.70      1803\n",
      "          -       0.69      0.63      0.66      1751\n",
      "\n",
      "avg / total       0.68      0.68      0.68      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.215532\n",
      "Error (Misclassification) Test: 0.321047\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.892234\n",
      "Test Accuracy LOGISTIC: 0.719111\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.72      0.71      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.107766\n",
      "Error (Misclassification) Test: 0.280810\n",
      "Usando C= 1.000000\n",
      "Training Accuracy LOGISTIC: 0.989589\n",
      "Test Accuracy LOGISTIC: 0.721362\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.72      1803\n",
      "          -       0.72      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.010411\n",
      "Error (Misclassification) Test: 0.278559\n",
      "Usando C= 1.000000\n",
      "Training Accuracy LOGISTIC: 0.989589\n",
      "Test Accuracy LOGISTIC: 0.721362\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.72      1803\n",
      "          -       0.72      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.010411\n",
      "Error (Misclassification) Test: 0.278559\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.718548\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.000000\n",
      "Error (Misclassification) Test: 0.281373\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.714044\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.71      0.72      1803\n",
      "          -       0.71      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.000000\n",
      "Error (Misclassification) Test: 0.285875\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.712356\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.71      0.71      1803\n",
      "          -       0.70      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.000000\n",
      "Error (Misclassification) Test: 0.287563\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def do_LOGIT(x,y,xt,yt):\n",
    "    start_t = time.time()\n",
    "    Cs = [0.01,0.1,1,1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"Usando C= %f\"%C\n",
    "        model = LogisticRegression(penalty='l2',C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"LOGISTIC\")\n",
    "        #Se calculan y muestran los errores\n",
    "        error,terror = errors(model,x,y,xt,yt)\n",
    "        print \"Error (Misclassification) Training: %f\"%(error)\n",
    "        print \"Error (Misclassification) Test: %f\"%(terror)\n",
    "print \"EFFECT OF C IN THE MODEL\"\n",
    "features_train,labels_train,features_test,labels_test = representacion(\"lem\")\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso anterior se ajusta un modelo de <b>Regresión Logística Regularizado</b>, donde recibe de parámetro un valor <i>C</i> el cual se analiza su efecto en el desempeño del modelo en el test set y en el training set. Este parámetro <i>C</i> representa el rango de la penalización del modelo a equivocarse sobre el conjunto del cual se entrena, es decir, el error sobre el. Para valores pequeños de <i>C</i> el modelo está permite bajos valores de penalización, por lo que el modelo es mas relajado en permitir un mayor error sobre el training set, mostrando esto en que el desempeño sobre el training set es el peor. Con un <i>C</i> muy bajo se tiene que el modelo pasa a ser muy relajado por lo que presenta un menor desempeño en el test set. \n",
    "Cuando <i>C</i> es mayor a 10, se pueden ver modelos no relajados, es decir con una mayor penalización sobre el error en el training set, por lo que el modelo se ajusta a este set produciendo un error de entrenamiento de 0 (desempeño 100%). Se puede visualizar esta transición en lo mostrado anteriormente, ya que a medida que aumenta el parámetro, el desempeño en el training set también."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT STOP WORDS and WITH LEMM\n",
      "Training Accuracy LOGISTIC: 0.987901\n",
      "Test Accuracy LOGISTIC: 0.736279\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.73      0.74      1803\n",
      "          -       0.73      0.74      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.012099\n",
      "Error (Misclassification) Test: 0.263647\n",
      "WITH LEMMATISATION\n",
      "Training Accuracy LOGISTIC: 0.989589\n",
      "Test Accuracy LOGISTIC: 0.721362\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.72      1803\n",
      "          -       0.72      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.010411\n",
      "Error (Misclassification) Test: 0.278559\n",
      "WITH STEMMING\n",
      "Training Accuracy LOGISTIC: 0.981148\n",
      "Test Accuracy LOGISTIC: 0.735153\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.74      0.74      1803\n",
      "          -       0.73      0.73      0.73      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.018852\n",
      "Error (Misclassification) Test: 0.264772\n"
     ]
    }
   ],
   "source": [
    "#SEGUN LO DE ARRIBA SE ESCOGE C = 1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def do_LOGIT_C(x,y,xt,yt,c=1):\n",
    "    start_t = time.time()\n",
    "    model = LogisticRegression(penalty='l2',C=c)\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"LOGISTIC\")\n",
    "    return model\n",
    "\n",
    "errors_logit = []\n",
    "accuracy_logit = []\n",
    "\n",
    "tipos = [\"normal\",\"lem\",\"stem\"]\n",
    "descripcion = [\"WITHOUT STOP WORDS and WITH LEMM\", \"WITH LEMMATISATION\",\"WITH STEMMING\"]\n",
    "for r, d in zip(tipos,descripcion): #for para mostrar el efecto de distintas representaciones\n",
    "    print d\n",
    "    features_train,labels_train,features_test,labels_test =  representacion(r)\n",
    "    model = do_LOGIT_C(features_train,labels_train,features_test,labels_test) #se ajusta un modelo LOGISTICO\n",
    "    \n",
    "    #calculan y guardan los errores de entrenamiento y prueba\n",
    "    error,terror = errors(model,features_train,labels_train,features_test,labels_test) \n",
    "    errors_logit.append([error,terror])\n",
    "    print \"Error (Misclassification) Training: %f\"%(error)\n",
    "    print \"Error (Misclassification) Test: %f\"%(terror)\n",
    "    \n",
    "    #valores de retornos agregados por datos requeridos en grafico\n",
    "    acc = model.score(features_test,labels_test)\n",
    "    acct = model.score(features_train,labels_train)\n",
    "    prec_rec = precision_recall_fscore_support(labels_test,model.predict(features_test))[:1] #solo pre y rec\n",
    "    datos = [acc,acct] + list(prec_rec[0])\n",
    "    accuracy_logit.append(datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda superior se ajustó un modelo de Regresión Lineal Regularizada con parámetro <i>C </i> igual a 1, mostrando el efecto de utilizar <i>stemming </i> o <i>lemmatisation</i> en la representación de los datos. Para esto se puede ver que la representación mediante <i>stemming</i> se comporta mejor sobre el test set, produciendo un buen desempeño en todas las métricas presentadas anteriormente (precision, recall, f1-score), además de presentar un desempeño sobre el test set de <b>73,51 %</b>. Esto se explica al igual que en los casos anteriores de Naive Bayes, debido a que este proceso es mejor ya que se trabaja con información pura (palabras en su tronco léxico).\n",
    "\n",
    "El filtrar el proceso de <b>stopwords</b> al igual que en los casos anteriores presenta un mejor comportamiendo sobre el test set, debido al mismo razonamiento de que es producido por que en este caso el training set genera una serie de probabilidades en las palabras que elimina el <b>stopwords</b> las cuales benefician al momento de ver el desempeño sobre el test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EFFECT OF C IN THE MODEL\n",
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.884637\n",
      "Test Accuracy SVM: 0.715170\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.71      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.989589\n",
      "Test Accuracy SVM: 0.723614\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.73      1803\n",
      "          -       0.72      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 1.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.710667\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.70      0.71      1803\n",
      "          -       0.70      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.702786\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.698565\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.697439\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.70      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "def do_SVM(x,y,xt,yt):\n",
    "    Cs = [0.01,0.1,1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"El valor de C que se esta probando: %f\"%C\n",
    "        model = LinearSVC(C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"SVM\")\n",
    "print \"EFFECT OF C IN THE MODEL\"\n",
    "features_train,labels_train,features_test,labels_test = representacion(\"lem\")\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Para lo presentado en la celda anterior se tiene un modelo <b>SVM</b> el cual es ajustado al training set analizando su comportamiendo en base al parámetro de penalización <i>C</i>, donde este valor representa el error presente en el ajuste del modelo sobre el training set, en otras palabras, representa el grado de suavidad del modelo. Para <i>C</i> pequeños el modelo penaliza menos los errores sobre el ajuste en el trainng set, traduciendose en un modelo mas suave (</i>soft-margin</i>) el cual permite errores sobre los datos en los cuales se ajusta. Para <i>C</i> grande la penalización sobre el error en el conjunto con el cual se entrena es mayor, traduciéndose en un modelo mas estricto (<i>hard-margin</i>) sobre el training set.\n",
    "\n",
    "Para este dataset de opiniones sobre películas se puede ver el efecto esperado del parámetro <i>C</i> sobre el modelo <b>SVM</b>, donde con valores pequeños el desempeño sobre el training set es bajo comparado con otro valor de <i>C</i>. Para <i>C</i> mayor a 1 el modelo es de <i>hard-margin</i>, es decir es estricto sobre el training set, traduciéndose en un desempeño de 100% sobre este set y con un menor desempeño sobre el test set, produciéndo un claro <i>overfitting</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT STOP WORDS and WITH LEMM\n",
      "Training Accuracy SVM: 0.987901\n",
      "Test Accuracy SVM: 0.738249\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.012099\n",
      "Error (Misclassification) Test: 0.261677\n",
      "WITH LEMMATISATION\n",
      "Training Accuracy SVM: 0.989589\n",
      "Test Accuracy SVM: 0.723614\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.73      1803\n",
      "          -       0.72      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.010411\n",
      "Error (Misclassification) Test: 0.276308\n",
      "WITH STEMMING\n",
      "Training Accuracy SVM: 0.981992\n",
      "Test Accuracy SVM: 0.731213\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.73      0.73      1803\n",
      "          -       0.73      0.73      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Error (Misclassification) Training: 0.018008\n",
      "Error (Misclassification) Test: 0.268711\n"
     ]
    }
   ],
   "source": [
    "#SEGUN LO DE ARRIBA SE ESCOGE C = 0.1\n",
    "from sklearn.svm import LinearSVC\n",
    "def do_SVM_C(x,y,xt,yt,c=0.1):\n",
    "    model = LinearSVC(C=c)\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"SVM\")\n",
    "    return model\n",
    "errors_svm = []\n",
    "accuracy_svm = []\n",
    "\n",
    "tipos = [\"normal\",\"lem\",\"stem\"]\n",
    "descripcion = [\"WITHOUT STOP WORDS and WITH LEMM\", \"WITH LEMMATISATION\",\"WITH STEMMING\"]\n",
    "for r, d in zip(tipos,descripcion): #for para mostrar el efecto de distintas representaciones\n",
    "    print d\n",
    "    features_train,labels_train,features_test,labels_test =  representacion(r)\n",
    "    model = do_SVM_C(features_train,labels_train,features_test,labels_test) #es ejecutado SVM retornando el modelo ajustado\n",
    "    \n",
    "    #calculan y guardan los errores de entrenamiento y prueba\n",
    "    error,terror = errors(model,features_train,labels_train,features_test,labels_test) \n",
    "    errors_svm.append([error,terror])\n",
    "    print \"Error (Misclassification) Training: %f\"%(error)\n",
    "    print \"Error (Misclassification) Test: %f\"%(terror)\n",
    "    \n",
    "    #valores de retornos agregados por datos requeridos en grafico\n",
    "    acc = model.score(features_test,labels_test)\n",
    "    acct = model.score(features_train,labels_train)\n",
    "    prec_rec = precision_recall_fscore_support(labels_test,model.predict(features_test))[:1]\n",
    "    datos = [acc,acct] + list(prec_rec[0])\n",
    "    accuracy_svm.append(datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En la celda superior se ajusta un modelo de <b>SVM</b> con parámetro <i>C</i> igual a 0.1 para ver el efecto de realizar distintas representaciones verbales sobre el dataset. Para el caso de la representación según <i>stemming</i> se tiene un mejor desempeño sobre el test set, entregando una precisión de <b>73,12%</b>, esto se atribuye a la misma explicación ya dada anteriormente con los otros modelos.\n",
    "\n",
    "Para el caso de filtrar <b>stopwords</b> en el proceso del modelo este presenta un mejor desempeño sobre el test set, caso contradictorio a lo esperado al igual que en los 3 modelos ya descritos anteriormente, esto deja claro que el training set tiene un sesgo a realizar un ajuste mejor sobre el test set cuando son utilizadas estas palabras que no entrengan información. Un ejemplo de este suceso podría presentarse que en el caso en que el conector \"and\" aparezca en una gran cantidad de opiniones <i>positivas</i>, esto ayudará a que el modelo prediga mejor sobre el test set, pero es un caso específico de los dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1kAAAI6CAYAAADVFoJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb5d2b91390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Construir grafico comparativo.\n",
    "import matplotlib.pyplot as plt\n",
    "nostop = errors_bayes[0] + errors_multi[0] + errors_logit[0] + errors_svm[0]\n",
    "lem = errors_bayes[1] + errors_multi[1] + errors_logit[1] + errors_svm[1]\n",
    "stem = errors_bayes[2] + errors_multi[2] + errors_logit[2] + errors_svm[2]\n",
    "\n",
    "#PARA COMPARAR LOS EFECTOS DE STEM Y LEM\n",
    "colors = ['b','r','b','r','b','r','b','r']\n",
    "f, axarr = plt.subplots(2, 2, figsize=(12,8) )\n",
    "barlist = axarr[0, 0].bar(range(8), nostop, width  = 0.5, align = \"center\", color = colors)\n",
    "axarr[0, 0].set_title('Without stop words and lem')\n",
    "axarr[0, 0].set_xticks([0.5,2.5,4.5,6.5])\n",
    "axarr[0, 0].set_xticklabels(('Naive Bayes', 'Multinomial', 'Logistic','SVM'))\n",
    "axarr[0, 0].set_ylabel('Error')\n",
    "axarr[0, 0].legend(barlist, [\"Training\",\"Test\"], loc=\"center right\", fancybox= True)\n",
    "\n",
    "axarr[0, 1].bar(range(8), lem, width  = 0.5, align = \"center\", color = colors)\n",
    "axarr[0, 1].set_title('With lem')\n",
    "axarr[0, 1].set_xticks([0.5,2.5,4.5,6.5])\n",
    "axarr[0, 1].set_xticklabels(('Naive Bayes', 'Multinomial', 'Logistic','SVM'))\n",
    "axarr[0, 1].set_ylabel('Error')\n",
    "axarr[0, 1].legend(barlist, [\"Training\",\"Test\"], loc=\"center right\", fancybox= True)\n",
    "\n",
    "axarr[1, 0].bar(range(8), stem, width  = 0.5, align = \"center\", color = colors)\n",
    "axarr[1, 0].set_title('With stem')\n",
    "axarr[1, 0].set_xticks([0.5,2.5,4.5,6.5])\n",
    "axarr[1, 0].set_xticklabels(('Naive Bayes', 'Multinomial', 'Logistic','SVM'))\n",
    "axarr[1, 0].set_ylabel('Error')\n",
    "axarr[1, 0].legend(barlist, [\"Training\",\"Test\"],loc=\"center right\", fancybox= True)\n",
    "\n",
    "\n",
    "f.tight_layout() #separar los subplot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En este item se presentan los gráficos que resumen el error según misclassification de todos los modelos ajustados sobre el training set del dataset de <b>Rotten Tomatoes</b>. Donde se asigna un error máximo cuando el modelo se equivoca en predecir una etiqueta, para este caso por ejemplo es cuando el modelo predice una etiqueta como <i>positiva</i> siendo que es <i>negativa</i>. Se puede ver que para el caso en que la representación según  <i>lemmatisation</i>  los modelos Logístico y SVM presentan un <i>overfitting</i>  ya que estos se ajustan mucho al training set, en esta representación el modelo que mejor se comporta presentando el menor error en el test set y con menor overfitting es el de <b>Naive Bayes</b>. \n",
    "\n",
    "Para el caso que se utiliza la representación según <i>stemming</i> los modelos Logístico y SVM también presentan este sobre-ajuste sobre el training set. El modelo que mejor se comporta sobre test set según esta representación es el <b>Multinomial</b>.\n",
    "\n",
    "Se puede observar que cuando se usa lematization <b>sin stopwords</b>, se obtiene un error levemente mas bajo, lo cual es contradictorio puesto que como bien se ha mencionado anteriormente, stopword elimina las palabras que no aportan significado a la hora de clasificar, por lo que no aplicar este procedimiento podría producir un sesgo significativo.\n",
    "Para este caso en específico, como no se aplica stopword, el sesgo que se produce justamente ayuda un poco a bajar el error de test, es decir, a clasificar correctamente. Esto se puede explicar ya que ciertas palabras sin significado en el training set, tales como conectores, estén más presentes en clases positivas o negativas segun sea el caso, por lo que considerar estas palabras ciertamente provoca una mejora en la clasificación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1kAAALKCAYAAADAhJtqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb5d1f36510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#DECODIFAN LOS DATOS ALMACENADOS EN LAS CELDAS ANTERIORES\n",
    "nostop_ac = accuracy_bayes[0] + accuracy_multi[0] + accuracy_logit[0] + accuracy_svm[0]\n",
    "lem_ac = [accuracy_bayes[1]] + [accuracy_multi[1]] + [accuracy_logit[1]] + [accuracy_svm[1]]\n",
    "stem_ac = [accuracy_bayes[2]] + [accuracy_multi[2]] + [accuracy_logit[2]] + [accuracy_svm[2]]    \n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "accuracy_lem = []\n",
    "accuracy_stem = []\n",
    "for lem,stem in zip(lem_ac,stem_ac):\n",
    "    accuracy_lem += lem[:2]  \n",
    "    accuracy_stem += stem[:2]\n",
    "    precision += [lem[2]]+[stem[2]] \n",
    "    recall+= [lem[3]]+[stem[3]] \n",
    "    \n",
    "#PARA COMPARAR PRECISION Y RECALL\n",
    "f, axarr = plt.subplots(2, 2, figsize=(12,10) )\n",
    "colors = ['#0B9014','#D20BD2']*4\n",
    "barlist = axarr[0, 0].bar(range(8), precision, width  = 0.5, align = \"center\", color = colors)\n",
    "axarr[0, 0].set_title('Comparison of metric precision in differents models')\n",
    "axarr[0, 0].set_xticks([0.5,2.5,4.5,6.5])\n",
    "axarr[0, 0].set_xticklabels(('Naive Bayes', 'Multinomial', 'Logistic','SVM'))\n",
    "axarr[0, 0].set_ylabel('precision')\n",
    "axarr[0, 0].legend(barlist, [\"Lemmatisation\",\"Stemming\"],loc=\"center right\", fancybox= True)\n",
    "\n",
    "axarr[0, 1].bar(range(8), recall, width  = 0.5, align = \"center\", color = colors)\n",
    "axarr[0, 1].set_title('Comparison of metric recall in diferrents models')\n",
    "axarr[0, 1].set_xticks([0.5,2.5,4.5,6.5])\n",
    "axarr[0, 1].set_xticklabels(('Naive Bayes', 'Multinomial', 'Logistic','SVM'))\n",
    "axarr[0, 1].set_ylabel('recall')\n",
    "axarr[0, 1].legend(barlist, [\"Lemmatisation\",\"Stemming\"],loc=\"center right\", fancybox= True)\n",
    "\n",
    "#PARA COMPARAR LOS EFECTOS DE STEM Y LEM\n",
    "colors = ['#014105','#6BB970']*4\n",
    "barlist = axarr[1, 0].bar(range(8), accuracy_lem, width  = 0.5, align = \"center\", color = colors)\n",
    "axarr[1, 0].set_title('Representation by Lemmatisation')\n",
    "axarr[1, 0].set_xticks([0.5,2.5,4.5,6.5])\n",
    "axarr[1, 0].set_xticklabels(('Naive Bayes', 'Multinomial', 'Logistic','SVM'))\n",
    "axarr[1, 0].set_ylabel('Accuracy')\n",
    "axarr[1, 0].legend(barlist, [\"Test\",\"Training\"], loc=\"center right\", fancybox= True)\n",
    "\n",
    "colors = ['#520052','#FF3CFF']*4\n",
    "barlist = axarr[1, 1].bar(range(8), accuracy_stem, width  = 0.5, align = \"center\", color = colors)\n",
    "axarr[1, 1].set_title('Representation by Stemming')\n",
    "axarr[1, 1].set_xticks([0.5,2.5,4.5,6.5])\n",
    "axarr[1, 1].set_xticklabels(('Naive Bayes', 'Multinomial', 'Logistic','SVM'))\n",
    "axarr[1, 1].set_ylabel('Accuracy')\n",
    "axarr[1, 1].legend(barlist, [\"Test\",\"Training\"],loc=\"center right\", fancybox= True)\n",
    "\n",
    "\n",
    "f.tight_layout() #separar los subplot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Precision y Recall\n",
    "Al analizar la métrica de <b>precision</b> se puede ver que en general ningún método sobresale sobre el resto, teniendo todos un comportamiento similar con la representación mediante <i>lemmatisation</i> y <i>stemming</i>. Como la métrica precision significa el no etiquetar incorrectamente ejemplos que no son pertenecientes a la clase, se puede ver que esto no es fuertemente dependiente de la representación con la cual se trabaje y tampoco del modelo con el cual se ajusten los datos. Se puede ver que el modelo que tiene mejor <i>precision</i> es el <b>Multinomial</b> con representación mediante <i>stemming</i>.\n",
    "\n",
    "Al analizar la métrica de <b>recall</b> se puede ver al mismo caso que en el gráfico comentado anteriormente ya que ningún método sobresale sobre el resto. Como la métrica recall significa el no etiquetar incorrectamente ejemplos que so pertenecientes a la clase, se puede ver que esto no es fuertemente dependiente de la representación con la cual se trabaje y tampoco del modelo con el cual se ajusten los datos. El modelo que presenta un mejor valor en <i>recall</i> es el <b>Multinomial</b> con representación mediante <i>stemming</i>. Estos gráficos los cuales presentan métricas de desempeño positivo, muestran que en ningún caso la representación mediante <i>lemmatisation</i> logra un mayor desempeño.\n",
    "\n",
    "### Lemmatisation y Stemming\n",
    "Al analizar la <b>accuracy</b> (precisión) de los distintos modelos mediante las distintas representaciones, se puede ver que <i>lemmatisation</i> ofrece valores mas altos en la precisión sobre el training set, lo cual en este caso se traduce en un <i>overfitting</i>. La representación mediante <i>stemming</i> posee un comportamiento mejor, ya que los valores de la precisión sobre el test set  son mayores y estos producen un menor <i>overfitting</i> que el caso con <i>lemmatisation</i>.  Se puede concluir en base a los análisis anteriores que la representación mediante <i>stemming</i> es la que mejor se comporta para este dataset, gracias a su filtrado mas estricto permitiendo que palabras que significan lo mismo se reduzcan al mismo tronco léxico.\n",
    "\n",
    "\n",
    "Se puede ver que en general los mejores clasificadores para este dataset son los basados en <b>Bayes</b> (Naive Bayes y Naive Bayes Multinomial)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
